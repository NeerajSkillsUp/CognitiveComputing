{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Ques 1: Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports,\n",
        "technology, food, books, etc.).\n",
        "1. Convert text to lowercase and remove punctuation.\n",
        "2. Tokenize the text into words and sentences.\n",
        "3. Remove stopwords (using NLTK's stopwords list).\n",
        "4. Display word frequency distribution (excluding stopwords)."
      ],
      "metadata": {
        "id": "SG6nF1rd4yYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "paragraph = \"\"\"The vastness of space has always fascinated humanity.\n",
        "               Exploring distant galaxies, discovering exoplanets, and searching for extraterrestrial life drive scientific progress.\n",
        "               Missions like the James Webb Telescope reveal stunning cosmic phenomena, while Mars rovers hunt for signs of ancient life.\n",
        "               Private companies like SpaceX aim to make interstellar travel a reality.\n",
        "               Every breakthrough brings us closer to understanding our place in the universe.\"\"\"\n",
        "\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('','',string.punctuation))\n",
        "    return text\n",
        "\n",
        "cleaned_text = clean_text(paragraph)\n",
        "print(\"Lowercase + No Punctuation:\\n\",cleaned_text)\n",
        "\n",
        "words=word_tokenize(cleaned_text)\n",
        "sentences=sent_tokenize(paragraph)\n",
        "\n",
        "print(\"\\n2. Tokenization:\")\n",
        "print(\"- Words:\", words)\n",
        "print(\"- Sentences:\", sentences)\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "print(\"\\n3. After Stopword Removal:\\n\", filtered_words)\n",
        "print(\"\\n \",stopwords.words('english'))\n",
        "\n",
        "fdist = FreqDist(filtered_words)\n",
        "print(\"\\n4. Word Frequency Distribution:\")\n",
        "for word,freq in fdist.most_common():\n",
        "    print(f\"{word:15}: {freq}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2vu5yjJ5XQt",
        "outputId": "2002cf52-fcb9-4474-a904-f861db7496ba"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercase + No Punctuation:\n",
            " the vastness of space has always fascinated humanity \n",
            "               exploring distant galaxies discovering exoplanets and searching for extraterrestrial life drive scientific progress \n",
            "               missions like the james webb telescope reveal stunning cosmic phenomena while mars rovers hunt for signs of ancient life \n",
            "               private companies like spacex aim to make interstellar travel a reality \n",
            "               every breakthrough brings us closer to understanding our place in the universe\n",
            "\n",
            "2. Tokenization:\n",
            "- Words: ['the', 'vastness', 'of', 'space', 'has', 'always', 'fascinated', 'humanity', 'exploring', 'distant', 'galaxies', 'discovering', 'exoplanets', 'and', 'searching', 'for', 'extraterrestrial', 'life', 'drive', 'scientific', 'progress', 'missions', 'like', 'the', 'james', 'webb', 'telescope', 'reveal', 'stunning', 'cosmic', 'phenomena', 'while', 'mars', 'rovers', 'hunt', 'for', 'signs', 'of', 'ancient', 'life', 'private', 'companies', 'like', 'spacex', 'aim', 'to', 'make', 'interstellar', 'travel', 'a', 'reality', 'every', 'breakthrough', 'brings', 'us', 'closer', 'to', 'understanding', 'our', 'place', 'in', 'the', 'universe']\n",
            "- Sentences: ['The vastness of space has always fascinated humanity.', 'Exploring distant galaxies, discovering exoplanets, and searching for extraterrestrial life drive scientific progress.', 'Missions like the James Webb Telescope reveal stunning cosmic phenomena, while Mars rovers hunt for signs of ancient life.', 'Private companies like SpaceX aim to make interstellar travel a reality.', 'Every breakthrough brings us closer to understanding our place in the universe.']\n",
            "\n",
            "3. After Stopword Removal:\n",
            " ['vastness', 'space', 'always', 'fascinated', 'humanity', 'exploring', 'distant', 'galaxies', 'discovering', 'exoplanets', 'searching', 'extraterrestrial', 'life', 'drive', 'scientific', 'progress', 'missions', 'like', 'james', 'webb', 'telescope', 'reveal', 'stunning', 'cosmic', 'phenomena', 'mars', 'rovers', 'hunt', 'signs', 'ancient', 'life', 'private', 'companies', 'like', 'spacex', 'aim', 'make', 'interstellar', 'travel', 'reality', 'every', 'breakthrough', 'brings', 'us', 'closer', 'understanding', 'place', 'universe']\n",
            "\n",
            "  ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n",
            "\n",
            "4. Word Frequency Distribution:\n",
            "life           : 2\n",
            "like           : 2\n",
            "vastness       : 1\n",
            "space          : 1\n",
            "always         : 1\n",
            "fascinated     : 1\n",
            "humanity       : 1\n",
            "exploring      : 1\n",
            "distant        : 1\n",
            "galaxies       : 1\n",
            "discovering    : 1\n",
            "exoplanets     : 1\n",
            "searching      : 1\n",
            "extraterrestrial: 1\n",
            "drive          : 1\n",
            "scientific     : 1\n",
            "progress       : 1\n",
            "missions       : 1\n",
            "james          : 1\n",
            "webb           : 1\n",
            "telescope      : 1\n",
            "reveal         : 1\n",
            "stunning       : 1\n",
            "cosmic         : 1\n",
            "phenomena      : 1\n",
            "mars           : 1\n",
            "rovers         : 1\n",
            "hunt           : 1\n",
            "signs          : 1\n",
            "ancient        : 1\n",
            "private        : 1\n",
            "companies      : 1\n",
            "spacex         : 1\n",
            "aim            : 1\n",
            "make           : 1\n",
            "interstellar   : 1\n",
            "travel         : 1\n",
            "reality        : 1\n",
            "every          : 1\n",
            "breakthrough   : 1\n",
            "brings         : 1\n",
            "us             : 1\n",
            "closer         : 1\n",
            "understanding  : 1\n",
            "place          : 1\n",
            "universe       : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 2 : Stemming and Lemmatization\n",
        "1. Take the tokenized words from Question 1 (after stopword removal).\n",
        "2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
        "3. Apply lemmatization using NLTK's WordNetLemmatizer.\n",
        "4. Compare and display results of both techniques."
      ],
      "metadata": {
        "id": "JvUYWkGUM_gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer,LancasterStemmer,WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "filtered_words = [\n",
        "    'vastness', 'space', 'always', 'fascinated', 'humanity', 'exploring',\n",
        "    'distant', 'galaxies', 'discovering', 'exoplanets', 'searching',\n",
        "    'extraterrestrial', 'life', 'drive', 'scientific', 'progress', 'missions',\n",
        "    'like', 'james', 'webb', 'telescope', 'reveal', 'stunning', 'cosmic',\n",
        "    'phenomena', 'mars', 'rovers', 'hunt', 'signs', 'ancient', 'life',\n",
        "    'private', 'companies', 'like', 'spacex', 'aim', 'make', 'interstellar',\n",
        "    'travel', 'reality', 'every', 'breakthrough', 'brings', 'us', 'closer',\n",
        "    'understanding', 'place', 'universe'\n",
        "]\n",
        "\n",
        "porter = PorterStemmer()\n",
        "porter_stems = [porter.stem(word) for word in filtered_words]\n",
        "\n",
        "lancaster = LancasterStemmer()\n",
        "lancaster_stems = [lancaster.stem(word) for word in filtered_words]\n",
        "\n",
        "# nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "print(f\"{'Original':<20} {'Porter':<20} {'Lancaster':<20} {'Lemma':<20}\")\n",
        "print(\"-\" * 80)\n",
        "for original, porter, lancaster, lemma in zip(filtered_words, porter_stems, lancaster_stems, lemmas):\n",
        "    print(f\"{original:<20} {porter:<20} {lancaster:<20} {lemma:<20}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7B0ll21NPoK",
        "outputId": "ac8e25d1-f280-4edc-e189-eadd3334d118"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original             Porter               Lancaster            Lemma               \n",
            "--------------------------------------------------------------------------------\n",
            "vastness             vast                 vast                 vastness            \n",
            "space                space                spac                 space               \n",
            "always               alway                alway                always              \n",
            "fascinated           fascin               fascin               fascinated          \n",
            "humanity             human                hum                  humanity            \n",
            "exploring            explor               expl                 exploring           \n",
            "distant              distant              dist                 distant             \n",
            "galaxies             galaxi               galaxy               galaxy              \n",
            "discovering          discov               discov               discovering         \n",
            "exoplanets           exoplanet            exoplanet            exoplanets          \n",
            "searching            search               search               searching           \n",
            "extraterrestrial     extraterrestri       extraterrest         extraterrestrial    \n",
            "life                 life                 lif                  life                \n",
            "drive                drive                driv                 drive               \n",
            "scientific           scientif             sci                  scientific          \n",
            "progress             progress             progress             progress            \n",
            "missions             mission              miss                 mission             \n",
            "like                 like                 lik                  like                \n",
            "james                jame                 jam                  james               \n",
            "webb                 webb                 web                  webb                \n",
            "telescope            telescop             telescop             telescope           \n",
            "reveal               reveal               rev                  reveal              \n",
            "stunning             stun                 stun                 stunning            \n",
            "cosmic               cosmic               cosm                 cosmic              \n",
            "phenomena            phenomena            phenomen             phenomenon          \n",
            "mars                 mar                  mar                  mar                 \n",
            "rovers               rover                rov                  rover               \n",
            "hunt                 hunt                 hunt                 hunt                \n",
            "signs                sign                 sign                 sign                \n",
            "ancient              ancient              ant                  ancient             \n",
            "life                 life                 lif                  life                \n",
            "private              privat               priv                 private             \n",
            "companies            compani              company              company             \n",
            "like                 like                 lik                  like                \n",
            "spacex               spacex               spacex               spacex              \n",
            "aim                  aim                  aim                  aim                 \n",
            "make                 make                 mak                  make                \n",
            "interstellar         interstellar         interstell           interstellar        \n",
            "travel               travel               travel               travel              \n",
            "reality              realiti              real                 reality             \n",
            "every                everi                every                every               \n",
            "breakthrough         breakthrough         breakthrough         breakthrough        \n",
            "brings               bring                bring                brings              \n",
            "us                   us                   us                   u                   \n",
            "closer               closer               clos                 closer              \n",
            "understanding        understand           understand           understanding       \n",
            "place                place                plac                 place               \n",
            "universe             univers              univers              universe            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 3: Regular Expressions and Text Splittng\n",
        "1. Take their original text from Question 1.\n",
        "2. Use regular expressions to:\n",
        "a. Extract all words with more than 5 letters.\n",
        "b. Extract all numbers (if any exist in their text).\n",
        "c. Extract all capitalized words.\n",
        "3. Use text splittng techniques to:\n",
        "a. Split the text into words containing only alphabets (removing digits and special\n",
        "characters).\n",
        "b. Extract words starting with a vowel."
      ],
      "metadata": {
        "id": "q7J8E8txRHG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"\"\"The vastness of space has always fascinated humanity.\n",
        "          Exploring distant galaxies, discovering exoplanets, and searching for extraterrestrial life drive scientific progress.\n",
        "          Missions like the James Webb Telescope reveal stunning cosmic phenomena, while Mars rovers hunt for signs of ancient life.\n",
        "          Private companies like SpaceX aim to make interstellar travel a reality.\n",
        "          Every breakthrough brings us closer to understanding our place in the universe.\"\"\"\n",
        "\n",
        "long_words = re.findall(r'\\b\\w{6,}\\b',text)\n",
        "print(\"Words with >5 letters:              \",long_words)\n",
        "\n",
        "numbers = re.findall(r'\\b\\d+\\b',text)\n",
        "print(\"Numbers found:                      \",numbers)\n",
        "\n",
        "capitalized_words = re.findall(r'\\b[A-Z][a-z]+\\b',text)\n",
        "print(\"Capitalized words:                  \",capitalized_words)\n",
        "\n",
        "clean_words = re.findall(r'\\b[a-zA-Z]+\\b',text)\n",
        "print(\"Alphabetic words only:              \",clean_words)\n",
        "\n",
        "vowel_words = re.findall(r'\\b[aeiouAEIOU][a-zA-Z]*\\b',text)\n",
        "print(\"Words starting with vowels:         \",vowel_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EleTNqB_RZnQ",
        "outputId": "3ded1dd6-8f6f-4037-e2fa-badd085707ba"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words with >5 letters:               ['vastness', 'always', 'fascinated', 'humanity', 'Exploring', 'distant', 'galaxies', 'discovering', 'exoplanets', 'searching', 'extraterrestrial', 'scientific', 'progress', 'Missions', 'Telescope', 'reveal', 'stunning', 'cosmic', 'phenomena', 'rovers', 'ancient', 'Private', 'companies', 'SpaceX', 'interstellar', 'travel', 'reality', 'breakthrough', 'brings', 'closer', 'understanding', 'universe']\n",
            "Numbers found:                       []\n",
            "Capitalized words:                   ['The', 'Exploring', 'Missions', 'James', 'Webb', 'Telescope', 'Mars', 'Private', 'Every']\n",
            "Alphabetic words only:               ['The', 'vastness', 'of', 'space', 'has', 'always', 'fascinated', 'humanity', 'Exploring', 'distant', 'galaxies', 'discovering', 'exoplanets', 'and', 'searching', 'for', 'extraterrestrial', 'life', 'drive', 'scientific', 'progress', 'Missions', 'like', 'the', 'James', 'Webb', 'Telescope', 'reveal', 'stunning', 'cosmic', 'phenomena', 'while', 'Mars', 'rovers', 'hunt', 'for', 'signs', 'of', 'ancient', 'life', 'Private', 'companies', 'like', 'SpaceX', 'aim', 'to', 'make', 'interstellar', 'travel', 'a', 'reality', 'Every', 'breakthrough', 'brings', 'us', 'closer', 'to', 'understanding', 'our', 'place', 'in', 'the', 'universe']\n",
            "Words starting with vowels:          ['of', 'always', 'Exploring', 'exoplanets', 'and', 'extraterrestrial', 'of', 'ancient', 'aim', 'interstellar', 'a', 'Every', 'us', 'understanding', 'our', 'in', 'universe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques 4: Custom Tokenization & Regex-based Text Cleaning\n",
        "1. Take original text from Question 1.\n",
        "2. Write a custom tokenization function that:\n",
        "a. Removes punctuation and special symbols, but keeps contractions (e.g.,\n",
        "\"isn't\" should not be split into \"is\" and \"n't\").\n",
        "b. Handles hyphenated words as a single token (e.g., \"state-of-the-art\" remains\n",
        "a single token).\n",
        "c. Tokenizes numbers separately but keeps decimal numbers intact (e.g., \"3.14\"\n",
        "should remain as is).\n",
        "\n",
        "3. Use Regex Substitutions (re.sub) to:\n",
        "a. Replace email addresses with '<EMAIL>' placeholder.\n",
        "b. Replace URLs with '<URL>' placeholder.\n",
        "c. Replace phone numbers (formats: 123-456-7890 or +91 9876543210) with\n",
        "'<PHONE>' placeholder."
      ],
      "metadata": {
        "id": "SHBHimJiU5JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"\"\"The vastness of space has always fascinated humanity. Exploring distant galaxies, discovering exoplanets, and searching for extraterrestrial life drive scientific progress.\n",
        "          Missions like the James Webb Telescope reveal stunning cosmic phenomena, while Mars rovers hunt for signs of ancient life.\n",
        "          Private companies like SpaceX aim to make interstellar travel a reality. Every breakthrough brings us closer to understanding our place in the universe.\n",
        "          Contact us at info@example.com or visit https://www.example.org. For support, call +1 (800) 555-1234 or 9876543210.\"\"\"\n",
        "\n",
        "def custom_tokenize(text):\n",
        "    contractions = r\"(?<!\\w)([a-zA-Z]+'[a-zA-Z]+)(?!\\w)\"           # (?<!\\w) check for word not just before ..i in (...isn't....) and (?!\\w) check after t..\n",
        "    hyphenated = r\"\\b[a-zA-Z]+(?:-[a-zA-Z]+)+\\b\"\n",
        "    decimals = r\"\\b\\d+\\.\\d+\\b\"\n",
        "    integers = r\"(?<!\\w)\\d+(?!\\w)\"\n",
        "\n",
        "    pattern = f\"({contractions}|{hyphenated}|{decimals}|{integers}|\\w+)\"\n",
        "    tokens = re.findall(pattern,text)\n",
        "    tokens = [token for group in tokens for token in group if token]\n",
        "    return tokens\n",
        "\n",
        "tokens = custom_tokenize(text)\n",
        "print(\"Custom Tokens:\",tokens)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b','<EMAIL>',text)\n",
        "    text = re.sub(r'https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+','<URL>',text)\n",
        "    text = re.sub(r'(?:\\+\\d{1,3}\\s?)?(?:\\(\\d{3}\\)|\\d{3})[-\\s]?\\d{3}[-\\s]?\\d{4}\\b','<PHONE>',text)\n",
        "    return text\n",
        "\n",
        "cleaned_text = clean_text(text)\n",
        "print(\"\\nCleaned Text:\",cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49fPFNDKV9Ie",
        "outputId": "1d591e2a-86bd-405d-eea6-2591d408ab95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Tokens: ['The', 'vastness', 'of', 'space', 'has', 'always', 'fascinated', 'humanity', 'Exploring', 'distant', 'galaxies', 'discovering', 'exoplanets', 'and', 'searching', 'for', 'extraterrestrial', 'life', 'drive', 'scientific', 'progress', 'Missions', 'like', 'the', 'James', 'Webb', 'Telescope', 'reveal', 'stunning', 'cosmic', 'phenomena', 'while', 'Mars', 'rovers', 'hunt', 'for', 'signs', 'of', 'ancient', 'life', 'Private', 'companies', 'like', 'SpaceX', 'aim', 'to', 'make', 'interstellar', 'travel', 'a', 'reality', 'Every', 'breakthrough', 'brings', 'us', 'closer', 'to', 'understanding', 'our', 'place', 'in', 'the', 'universe', 'Contact', 'us', 'at', 'info', 'example', 'com', 'or', 'visit', 'https', 'www', 'example', 'org', 'For', 'support', 'call', '1', '800', '555', '1234', 'or', '9876543210']\n",
            "\n",
            "Cleaned Text: The vastness of space has always fascinated humanity. Exploring distant galaxies, discovering exoplanets, and searching for extraterrestrial life drive scientific progress. \n",
            "          Missions like the James Webb Telescope reveal stunning cosmic phenomena, while Mars rovers hunt for signs of ancient life. \n",
            "          Private companies like SpaceX aim to make interstellar travel a reality. Every breakthrough brings us closer to understanding our place in the universe.\n",
            "          Contact us at <EMAIL> or visit <URL> For support, call <PHONE> or <PHONE>.\n"
          ]
        }
      ]
    }
  ]
}